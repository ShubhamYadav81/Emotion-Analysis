{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FinalTrainMajor.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YitSR-fkXv5l",
        "outputId": "796510cd-bfed-47ce-eda9-8616aa97b185"
      },
      "source": [
        "pip install tensorflow==2.1.0\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 50.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.33.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 48.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.35.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (50.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7542 sha256=3415a240be630e74f294f991fa82009b01aaf1e30e14d3bf83e3fcafd40744a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txxj1EE9bzg2",
        "outputId": "050576db-0c5e-4730-aad7-02dedb071caf"
      },
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEPyrpQucoU3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15fXp7_rcpi2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "136AvUf9b9nK",
        "outputId": "10c04333-6630-4cbf-a255-dd38bf6cbb77"
      },
      "source": [
        "pip install keras==2.3.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/18/2e1ef121e5560ac24c7ac9e363aa5fa7006c40563c989e7211aba95b793a/Keras-2.3.0-py2.py3-none-any.whl (377kB)\n",
            "\r\u001b[K     |▉                               | 10kB 21.9MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 28.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 33.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 35.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 51kB 36.7MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 39.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 25.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 22.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 102kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 143kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 194kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 204kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 215kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 245kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 256kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 266kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 286kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 296kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 317kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 337kB 23.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 348kB 23.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 358kB 23.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 368kB 23.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 23.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.3.0) (1.1.2)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.4.3\n",
            "    Uninstalling Keras-2.4.3:\n",
            "      Successfully uninstalled Keras-2.4.3\n",
            "Successfully installed keras-2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziZDszFKcHuu",
        "outputId": "734fb4e2-0b0a-4248-f695-f683e5f51c6b"
      },
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X_-kJ67crGj"
      },
      "source": [
        "!tar -xf /content/drive/My\\ Drive/fer2013.tar.gz"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZGDi1sEdO3D",
        "outputId": "cde7a324-e3ed-4acf-f1bf-5b7539e157cf"
      },
      "source": [
        "import sys, os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
        "from keras.losses import categorical_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import np_utils\n",
        "# pd.set_option('display.max_rows', 500)\n",
        "# pd.set_option('display.max_columns', 500)\n",
        "# pd.set_option('display.width', 1000)\n",
        "\n",
        "df=pd.read_csv('fer2013/fer2013.csv')\n",
        "\n",
        "# print(df.info())\n",
        "# print(df[\"Usage\"].value_counts())\n",
        "\n",
        "# print(df.head())\n",
        "X_train,train_y,X_test,test_y=[],[],[],[]\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    val=row['pixels'].split(\" \")\n",
        "    try:\n",
        "        if 'Training' in row['Usage']:\n",
        "           X_train.append(np.array(val,'float32'))\n",
        "           train_y.append(row['emotion'])\n",
        "        elif 'PublicTest' in row['Usage']:\n",
        "           X_test.append(np.array(val,'float32'))\n",
        "           test_y.append(row['emotion'])\n",
        "    except:\n",
        "        print(f\"error occured at index :{index} and row:{row}\")\n",
        "\n",
        "\n",
        "num_features = 64\n",
        "num_labels = 7\n",
        "batch_size = 64\n",
        "epochs = 300\n",
        "width, height = 48, 48\n",
        "\n",
        "\n",
        "X_train = np.array(X_train,'float32')\n",
        "train_y = np.array(train_y,'float32')\n",
        "X_test = np.array(X_test,'float32')\n",
        "test_y = np.array(test_y,'float32')\n",
        "\n",
        "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
        "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)\n",
        "\n",
        "#cannot produce\n",
        "#normalizing data between oand 1\n",
        "X_train -= np.mean(X_train, axis=0)\n",
        "X_train /= np.std(X_train, axis=0)\n",
        "\n",
        "X_test -= np.mean(X_test, axis=0)\n",
        "X_test /= np.std(X_test, axis=0)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "# print(f\"shape:{X_train.shape}\")\n",
        "##designing the cnn\n",
        "#1st convolution layer\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
        "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#2nd convolution layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#3rd convolution layer\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "#fully connected neural networks\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "#Compliling the model\n",
        "model.compile(loss=categorical_crossentropy,\n",
        "              optimizer=Adam(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#Training the model\n",
        "model.fit(X_train, train_y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, test_y),\n",
        "          shuffle=True)\n",
        "\n",
        "\n",
        "#Saving the  model to  use it later on\n",
        "fer_json = model.to_json()\n",
        "with open(\"fer1.json\", \"w\") as json_file:\n",
        "    json_file.write(fer_json)\n",
        "model.save_weights(\"fer1.h5\")\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 28709 samples, validate on 3589 samples\n",
            "Epoch 1/300\n",
            "28709/28709 [==============================] - 10s 346us/step - loss: 1.7437 - accuracy: 0.2789 - val_loss: 1.5868 - val_accuracy: 0.3798\n",
            "Epoch 2/300\n",
            "28709/28709 [==============================] - 9s 319us/step - loss: 1.5367 - accuracy: 0.3940 - val_loss: 1.4299 - val_accuracy: 0.4369\n",
            "Epoch 3/300\n",
            "28709/28709 [==============================] - 9s 321us/step - loss: 1.4239 - accuracy: 0.4462 - val_loss: 1.3354 - val_accuracy: 0.4845\n",
            "Epoch 4/300\n",
            "28709/28709 [==============================] - 9s 323us/step - loss: 1.3572 - accuracy: 0.4745 - val_loss: 1.2932 - val_accuracy: 0.5018\n",
            "Epoch 5/300\n",
            "28709/28709 [==============================] - 9s 325us/step - loss: 1.3087 - accuracy: 0.4973 - val_loss: 1.2713 - val_accuracy: 0.5191\n",
            "Epoch 6/300\n",
            "28709/28709 [==============================] - 9s 322us/step - loss: 1.2774 - accuracy: 0.5061 - val_loss: 1.2372 - val_accuracy: 0.5339\n",
            "Epoch 7/300\n",
            "28709/28709 [==============================] - 9s 329us/step - loss: 1.2426 - accuracy: 0.5203 - val_loss: 1.2189 - val_accuracy: 0.5258\n",
            "Epoch 8/300\n",
            "28709/28709 [==============================] - 9s 328us/step - loss: 1.2178 - accuracy: 0.5344 - val_loss: 1.1977 - val_accuracy: 0.5447\n",
            "Epoch 9/300\n",
            "28709/28709 [==============================] - 9s 325us/step - loss: 1.1952 - accuracy: 0.5444 - val_loss: 1.1965 - val_accuracy: 0.5450\n",
            "Epoch 10/300\n",
            "28709/28709 [==============================] - 9s 327us/step - loss: 1.1734 - accuracy: 0.5513 - val_loss: 1.1929 - val_accuracy: 0.5450\n",
            "Epoch 11/300\n",
            "28709/28709 [==============================] - 9s 326us/step - loss: 1.1493 - accuracy: 0.5598 - val_loss: 1.1897 - val_accuracy: 0.5536\n",
            "Epoch 12/300\n",
            "28709/28709 [==============================] - 9s 326us/step - loss: 1.1375 - accuracy: 0.5644 - val_loss: 1.1708 - val_accuracy: 0.5542\n",
            "Epoch 13/300\n",
            "28709/28709 [==============================] - 9s 327us/step - loss: 1.1197 - accuracy: 0.5728 - val_loss: 1.1814 - val_accuracy: 0.5631\n",
            "Epoch 14/300\n",
            "28709/28709 [==============================] - 9s 326us/step - loss: 1.0992 - accuracy: 0.5785 - val_loss: 1.1778 - val_accuracy: 0.5528\n",
            "Epoch 15/300\n",
            "28709/28709 [==============================] - 9s 327us/step - loss: 1.0855 - accuracy: 0.5853 - val_loss: 1.1813 - val_accuracy: 0.5550\n",
            "Epoch 16/300\n",
            "28709/28709 [==============================] - 9s 328us/step - loss: 1.0644 - accuracy: 0.5949 - val_loss: 1.1763 - val_accuracy: 0.5520\n",
            "Epoch 17/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.0555 - accuracy: 0.5966 - val_loss: 1.1634 - val_accuracy: 0.5690\n",
            "Epoch 18/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 1.0448 - accuracy: 0.6041 - val_loss: 1.1853 - val_accuracy: 0.5539\n",
            "Epoch 19/300\n",
            "28709/28709 [==============================] - 9s 329us/step - loss: 1.0268 - accuracy: 0.6086 - val_loss: 1.1571 - val_accuracy: 0.5676\n",
            "Epoch 20/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 1.0053 - accuracy: 0.6177 - val_loss: 1.1656 - val_accuracy: 0.5737\n",
            "Epoch 21/300\n",
            "28709/28709 [==============================] - 9s 329us/step - loss: 0.9940 - accuracy: 0.6173 - val_loss: 1.1818 - val_accuracy: 0.5595\n",
            "Epoch 22/300\n",
            "28709/28709 [==============================] - 9s 329us/step - loss: 0.9818 - accuracy: 0.6245 - val_loss: 1.1863 - val_accuracy: 0.5528\n",
            "Epoch 23/300\n",
            "28709/28709 [==============================] - 9s 327us/step - loss: 0.9630 - accuracy: 0.6333 - val_loss: 1.1592 - val_accuracy: 0.5642\n",
            "Epoch 24/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.9517 - accuracy: 0.6395 - val_loss: 1.1928 - val_accuracy: 0.5706\n",
            "Epoch 25/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.9405 - accuracy: 0.6449 - val_loss: 1.1559 - val_accuracy: 0.5720\n",
            "Epoch 26/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.9162 - accuracy: 0.6499 - val_loss: 1.1897 - val_accuracy: 0.5634\n",
            "Epoch 27/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.9122 - accuracy: 0.6538 - val_loss: 1.2085 - val_accuracy: 0.5759\n",
            "Epoch 28/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.8991 - accuracy: 0.6584 - val_loss: 1.1980 - val_accuracy: 0.5665\n",
            "Epoch 29/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.8954 - accuracy: 0.6627 - val_loss: 1.1993 - val_accuracy: 0.5704\n",
            "Epoch 30/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.8754 - accuracy: 0.6664 - val_loss: 1.2177 - val_accuracy: 0.5673\n",
            "Epoch 31/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.8691 - accuracy: 0.6689 - val_loss: 1.2388 - val_accuracy: 0.5709\n",
            "Epoch 32/300\n",
            "28709/28709 [==============================] - 9s 329us/step - loss: 0.8581 - accuracy: 0.6722 - val_loss: 1.2587 - val_accuracy: 0.5603\n",
            "Epoch 33/300\n",
            "28709/28709 [==============================] - 10s 346us/step - loss: 0.8439 - accuracy: 0.6794 - val_loss: 1.2469 - val_accuracy: 0.5765\n",
            "Epoch 34/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.8248 - accuracy: 0.6878 - val_loss: 1.2494 - val_accuracy: 0.5678\n",
            "Epoch 35/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.8246 - accuracy: 0.6885 - val_loss: 1.2219 - val_accuracy: 0.5651\n",
            "Epoch 36/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.8034 - accuracy: 0.6968 - val_loss: 1.2854 - val_accuracy: 0.5706\n",
            "Epoch 37/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.7993 - accuracy: 0.6983 - val_loss: 1.2718 - val_accuracy: 0.5720\n",
            "Epoch 38/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.7883 - accuracy: 0.7012 - val_loss: 1.2815 - val_accuracy: 0.5687\n",
            "Epoch 39/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.7756 - accuracy: 0.7083 - val_loss: 1.2707 - val_accuracy: 0.5720\n",
            "Epoch 40/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.7630 - accuracy: 0.7099 - val_loss: 1.2684 - val_accuracy: 0.5743\n",
            "Epoch 41/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.7587 - accuracy: 0.7158 - val_loss: 1.2823 - val_accuracy: 0.5743\n",
            "Epoch 42/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.7563 - accuracy: 0.7159 - val_loss: 1.2827 - val_accuracy: 0.5637\n",
            "Epoch 43/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.7375 - accuracy: 0.7216 - val_loss: 1.2946 - val_accuracy: 0.5745\n",
            "Epoch 44/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.7261 - accuracy: 0.7263 - val_loss: 1.2970 - val_accuracy: 0.5600\n",
            "Epoch 45/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.7168 - accuracy: 0.7302 - val_loss: 1.3253 - val_accuracy: 0.5687\n",
            "Epoch 46/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.7074 - accuracy: 0.7321 - val_loss: 1.3226 - val_accuracy: 0.5637\n",
            "Epoch 47/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.7012 - accuracy: 0.7371 - val_loss: 1.3607 - val_accuracy: 0.5667\n",
            "Epoch 48/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.6960 - accuracy: 0.7378 - val_loss: 1.3309 - val_accuracy: 0.5609\n",
            "Epoch 49/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6829 - accuracy: 0.7450 - val_loss: 1.3514 - val_accuracy: 0.5659\n",
            "Epoch 50/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6715 - accuracy: 0.7501 - val_loss: 1.3465 - val_accuracy: 0.5759\n",
            "Epoch 51/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6791 - accuracy: 0.7487 - val_loss: 1.3799 - val_accuracy: 0.5584\n",
            "Epoch 52/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.6541 - accuracy: 0.7584 - val_loss: 1.3563 - val_accuracy: 0.5631\n",
            "Epoch 53/300\n",
            "28709/28709 [==============================] - 9s 329us/step - loss: 0.6499 - accuracy: 0.7562 - val_loss: 1.3788 - val_accuracy: 0.5756\n",
            "Epoch 54/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.6467 - accuracy: 0.7590 - val_loss: 1.4182 - val_accuracy: 0.5678\n",
            "Epoch 55/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6456 - accuracy: 0.7625 - val_loss: 1.4280 - val_accuracy: 0.5628\n",
            "Epoch 56/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.6364 - accuracy: 0.7648 - val_loss: 1.4067 - val_accuracy: 0.5653\n",
            "Epoch 57/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.6179 - accuracy: 0.7697 - val_loss: 1.3955 - val_accuracy: 0.5731\n",
            "Epoch 58/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.6267 - accuracy: 0.7669 - val_loss: 1.3711 - val_accuracy: 0.5731\n",
            "Epoch 59/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.6099 - accuracy: 0.7741 - val_loss: 1.3804 - val_accuracy: 0.5701\n",
            "Epoch 60/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.6098 - accuracy: 0.7766 - val_loss: 1.3972 - val_accuracy: 0.5787\n",
            "Epoch 61/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.5947 - accuracy: 0.7804 - val_loss: 1.3729 - val_accuracy: 0.5779\n",
            "Epoch 62/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.5992 - accuracy: 0.7813 - val_loss: 1.4115 - val_accuracy: 0.5692\n",
            "Epoch 63/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.5785 - accuracy: 0.7884 - val_loss: 1.4232 - val_accuracy: 0.5723\n",
            "Epoch 64/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5906 - accuracy: 0.7840 - val_loss: 1.4468 - val_accuracy: 0.5684\n",
            "Epoch 65/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.5836 - accuracy: 0.7839 - val_loss: 1.4136 - val_accuracy: 0.5676\n",
            "Epoch 66/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.5790 - accuracy: 0.7883 - val_loss: 1.4631 - val_accuracy: 0.5734\n",
            "Epoch 67/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.5669 - accuracy: 0.7937 - val_loss: 1.4297 - val_accuracy: 0.5715\n",
            "Epoch 68/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5512 - accuracy: 0.7970 - val_loss: 1.4673 - val_accuracy: 0.5692\n",
            "Epoch 69/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5613 - accuracy: 0.7948 - val_loss: 1.4543 - val_accuracy: 0.5701\n",
            "Epoch 70/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.5468 - accuracy: 0.8019 - val_loss: 1.4620 - val_accuracy: 0.5681\n",
            "Epoch 71/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5449 - accuracy: 0.7997 - val_loss: 1.4857 - val_accuracy: 0.5673\n",
            "Epoch 72/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5457 - accuracy: 0.8030 - val_loss: 1.4615 - val_accuracy: 0.5776\n",
            "Epoch 73/300\n",
            "28709/28709 [==============================] - 10s 341us/step - loss: 0.5262 - accuracy: 0.8090 - val_loss: 1.4533 - val_accuracy: 0.5715\n",
            "Epoch 74/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.5379 - accuracy: 0.8062 - val_loss: 1.5057 - val_accuracy: 0.5687\n",
            "Epoch 75/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5377 - accuracy: 0.8061 - val_loss: 1.4292 - val_accuracy: 0.5754\n",
            "Epoch 76/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.5259 - accuracy: 0.8102 - val_loss: 1.4640 - val_accuracy: 0.5676\n",
            "Epoch 77/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.5140 - accuracy: 0.8120 - val_loss: 1.5125 - val_accuracy: 0.5748\n",
            "Epoch 78/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.5101 - accuracy: 0.8134 - val_loss: 1.5324 - val_accuracy: 0.5651\n",
            "Epoch 79/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4999 - accuracy: 0.8179 - val_loss: 1.5207 - val_accuracy: 0.5592\n",
            "Epoch 80/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.5086 - accuracy: 0.8160 - val_loss: 1.4960 - val_accuracy: 0.5609\n",
            "Epoch 81/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.5077 - accuracy: 0.8167 - val_loss: 1.5511 - val_accuracy: 0.5587\n",
            "Epoch 82/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4957 - accuracy: 0.8185 - val_loss: 1.5602 - val_accuracy: 0.5681\n",
            "Epoch 83/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.5002 - accuracy: 0.8180 - val_loss: 1.5657 - val_accuracy: 0.5676\n",
            "Epoch 84/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4860 - accuracy: 0.8250 - val_loss: 1.6388 - val_accuracy: 0.5617\n",
            "Epoch 85/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4920 - accuracy: 0.8246 - val_loss: 1.4950 - val_accuracy: 0.5673\n",
            "Epoch 86/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.4857 - accuracy: 0.8264 - val_loss: 1.5436 - val_accuracy: 0.5620\n",
            "Epoch 87/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.4818 - accuracy: 0.8310 - val_loss: 1.5842 - val_accuracy: 0.5631\n",
            "Epoch 88/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4734 - accuracy: 0.8322 - val_loss: 1.5689 - val_accuracy: 0.5729\n",
            "Epoch 89/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.4646 - accuracy: 0.8356 - val_loss: 1.6793 - val_accuracy: 0.5612\n",
            "Epoch 90/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4753 - accuracy: 0.8302 - val_loss: 1.5283 - val_accuracy: 0.5673\n",
            "Epoch 91/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4638 - accuracy: 0.8344 - val_loss: 1.5399 - val_accuracy: 0.5704\n",
            "Epoch 92/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4652 - accuracy: 0.8372 - val_loss: 1.6357 - val_accuracy: 0.5645\n",
            "Epoch 93/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4691 - accuracy: 0.8321 - val_loss: 1.5690 - val_accuracy: 0.5784\n",
            "Epoch 94/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4577 - accuracy: 0.8368 - val_loss: 1.5461 - val_accuracy: 0.5642\n",
            "Epoch 95/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4551 - accuracy: 0.8380 - val_loss: 1.6206 - val_accuracy: 0.5648\n",
            "Epoch 96/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4452 - accuracy: 0.8419 - val_loss: 1.6691 - val_accuracy: 0.5681\n",
            "Epoch 97/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4497 - accuracy: 0.8396 - val_loss: 1.5572 - val_accuracy: 0.5734\n",
            "Epoch 98/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4470 - accuracy: 0.8402 - val_loss: 1.6459 - val_accuracy: 0.5709\n",
            "Epoch 99/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4421 - accuracy: 0.8438 - val_loss: 1.5768 - val_accuracy: 0.5678\n",
            "Epoch 100/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4410 - accuracy: 0.8447 - val_loss: 1.6289 - val_accuracy: 0.5612\n",
            "Epoch 101/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4323 - accuracy: 0.8458 - val_loss: 1.6317 - val_accuracy: 0.5620\n",
            "Epoch 102/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.4315 - accuracy: 0.8473 - val_loss: 1.6472 - val_accuracy: 0.5665\n",
            "Epoch 103/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4274 - accuracy: 0.8490 - val_loss: 1.6071 - val_accuracy: 0.5656\n",
            "Epoch 104/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4293 - accuracy: 0.8497 - val_loss: 1.6940 - val_accuracy: 0.5609\n",
            "Epoch 105/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.4268 - accuracy: 0.8492 - val_loss: 1.6581 - val_accuracy: 0.5676\n",
            "Epoch 106/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4235 - accuracy: 0.8516 - val_loss: 1.6815 - val_accuracy: 0.5759\n",
            "Epoch 107/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4242 - accuracy: 0.8496 - val_loss: 1.6261 - val_accuracy: 0.5656\n",
            "Epoch 108/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.4146 - accuracy: 0.8547 - val_loss: 1.6612 - val_accuracy: 0.5631\n",
            "Epoch 109/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4249 - accuracy: 0.8489 - val_loss: 1.6487 - val_accuracy: 0.5706\n",
            "Epoch 110/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4204 - accuracy: 0.8527 - val_loss: 1.6123 - val_accuracy: 0.5623\n",
            "Epoch 111/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4119 - accuracy: 0.8546 - val_loss: 1.6609 - val_accuracy: 0.5681\n",
            "Epoch 112/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.4217 - accuracy: 0.8496 - val_loss: 1.7253 - val_accuracy: 0.5656\n",
            "Epoch 113/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.4148 - accuracy: 0.8544 - val_loss: 1.6837 - val_accuracy: 0.5653\n",
            "Epoch 114/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.4089 - accuracy: 0.8566 - val_loss: 1.6141 - val_accuracy: 0.5676\n",
            "Epoch 115/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4031 - accuracy: 0.8598 - val_loss: 1.6481 - val_accuracy: 0.5709\n",
            "Epoch 116/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4066 - accuracy: 0.8570 - val_loss: 1.6884 - val_accuracy: 0.5670\n",
            "Epoch 117/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3941 - accuracy: 0.8614 - val_loss: 1.6985 - val_accuracy: 0.5787\n",
            "Epoch 118/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3985 - accuracy: 0.8629 - val_loss: 1.6925 - val_accuracy: 0.5690\n",
            "Epoch 119/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3923 - accuracy: 0.8638 - val_loss: 1.7179 - val_accuracy: 0.5620\n",
            "Epoch 120/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3904 - accuracy: 0.8623 - val_loss: 1.6867 - val_accuracy: 0.5737\n",
            "Epoch 121/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.4013 - accuracy: 0.8599 - val_loss: 1.7075 - val_accuracy: 0.5695\n",
            "Epoch 122/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3963 - accuracy: 0.8617 - val_loss: 1.6678 - val_accuracy: 0.5606\n",
            "Epoch 123/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3857 - accuracy: 0.8644 - val_loss: 1.6688 - val_accuracy: 0.5684\n",
            "Epoch 124/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3913 - accuracy: 0.8654 - val_loss: 1.6723 - val_accuracy: 0.5603\n",
            "Epoch 125/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3837 - accuracy: 0.8645 - val_loss: 1.6856 - val_accuracy: 0.5729\n",
            "Epoch 126/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3734 - accuracy: 0.8694 - val_loss: 1.7038 - val_accuracy: 0.5645\n",
            "Epoch 127/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3949 - accuracy: 0.8638 - val_loss: 1.6955 - val_accuracy: 0.5720\n",
            "Epoch 128/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3824 - accuracy: 0.8658 - val_loss: 1.7401 - val_accuracy: 0.5665\n",
            "Epoch 129/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3871 - accuracy: 0.8635 - val_loss: 1.6773 - val_accuracy: 0.5581\n",
            "Epoch 130/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3722 - accuracy: 0.8695 - val_loss: 1.6752 - val_accuracy: 0.5681\n",
            "Epoch 131/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3801 - accuracy: 0.8691 - val_loss: 1.6675 - val_accuracy: 0.5628\n",
            "Epoch 132/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3727 - accuracy: 0.8711 - val_loss: 1.7006 - val_accuracy: 0.5642\n",
            "Epoch 133/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3721 - accuracy: 0.8695 - val_loss: 1.7063 - val_accuracy: 0.5698\n",
            "Epoch 134/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3662 - accuracy: 0.8702 - val_loss: 1.7308 - val_accuracy: 0.5698\n",
            "Epoch 135/300\n",
            "28709/28709 [==============================] - 9s 330us/step - loss: 0.3777 - accuracy: 0.8722 - val_loss: 1.7401 - val_accuracy: 0.5534\n",
            "Epoch 136/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3558 - accuracy: 0.8760 - val_loss: 1.7707 - val_accuracy: 0.5612\n",
            "Epoch 137/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3660 - accuracy: 0.8750 - val_loss: 1.7216 - val_accuracy: 0.5606\n",
            "Epoch 138/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.3664 - accuracy: 0.8736 - val_loss: 1.6910 - val_accuracy: 0.5665\n",
            "Epoch 139/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3594 - accuracy: 0.8762 - val_loss: 1.7868 - val_accuracy: 0.5626\n",
            "Epoch 140/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3681 - accuracy: 0.8738 - val_loss: 1.7269 - val_accuracy: 0.5720\n",
            "Epoch 141/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3623 - accuracy: 0.8770 - val_loss: 1.7409 - val_accuracy: 0.5651\n",
            "Epoch 142/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3553 - accuracy: 0.8799 - val_loss: 1.7874 - val_accuracy: 0.5665\n",
            "Epoch 143/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3634 - accuracy: 0.8767 - val_loss: 1.7275 - val_accuracy: 0.5665\n",
            "Epoch 144/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3488 - accuracy: 0.8788 - val_loss: 1.7595 - val_accuracy: 0.5834\n",
            "Epoch 145/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3624 - accuracy: 0.8758 - val_loss: 1.7090 - val_accuracy: 0.5715\n",
            "Epoch 146/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3486 - accuracy: 0.8798 - val_loss: 1.7238 - val_accuracy: 0.5567\n",
            "Epoch 147/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3533 - accuracy: 0.8798 - val_loss: 1.8010 - val_accuracy: 0.5631\n",
            "Epoch 148/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3447 - accuracy: 0.8816 - val_loss: 1.8198 - val_accuracy: 0.5626\n",
            "Epoch 149/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3572 - accuracy: 0.8759 - val_loss: 1.7897 - val_accuracy: 0.5731\n",
            "Epoch 150/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3515 - accuracy: 0.8797 - val_loss: 1.7532 - val_accuracy: 0.5598\n",
            "Epoch 151/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3417 - accuracy: 0.8835 - val_loss: 1.7804 - val_accuracy: 0.5695\n",
            "Epoch 152/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3577 - accuracy: 0.8782 - val_loss: 1.7598 - val_accuracy: 0.5592\n",
            "Epoch 153/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3469 - accuracy: 0.8801 - val_loss: 1.8048 - val_accuracy: 0.5645\n",
            "Epoch 154/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3369 - accuracy: 0.8850 - val_loss: 1.8281 - val_accuracy: 0.5592\n",
            "Epoch 155/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3411 - accuracy: 0.8808 - val_loss: 1.8081 - val_accuracy: 0.5570\n",
            "Epoch 156/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3442 - accuracy: 0.8829 - val_loss: 1.8110 - val_accuracy: 0.5676\n",
            "Epoch 157/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3592 - accuracy: 0.8784 - val_loss: 1.8253 - val_accuracy: 0.5609\n",
            "Epoch 158/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3450 - accuracy: 0.8835 - val_loss: 1.7402 - val_accuracy: 0.5603\n",
            "Epoch 159/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3467 - accuracy: 0.8844 - val_loss: 1.8114 - val_accuracy: 0.5578\n",
            "Epoch 160/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3455 - accuracy: 0.8802 - val_loss: 1.7889 - val_accuracy: 0.5729\n",
            "Epoch 161/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3431 - accuracy: 0.8824 - val_loss: 1.8235 - val_accuracy: 0.5617\n",
            "Epoch 162/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.3297 - accuracy: 0.8883 - val_loss: 1.8181 - val_accuracy: 0.5659\n",
            "Epoch 163/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3253 - accuracy: 0.8870 - val_loss: 1.8275 - val_accuracy: 0.5681\n",
            "Epoch 164/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3386 - accuracy: 0.8844 - val_loss: 1.7246 - val_accuracy: 0.5656\n",
            "Epoch 165/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3391 - accuracy: 0.8859 - val_loss: 1.8131 - val_accuracy: 0.5587\n",
            "Epoch 166/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3379 - accuracy: 0.8847 - val_loss: 1.7529 - val_accuracy: 0.5639\n",
            "Epoch 167/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3339 - accuracy: 0.8862 - val_loss: 1.8677 - val_accuracy: 0.5617\n",
            "Epoch 168/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.3227 - accuracy: 0.8913 - val_loss: 1.8370 - val_accuracy: 0.5600\n",
            "Epoch 169/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3431 - accuracy: 0.8851 - val_loss: 1.8535 - val_accuracy: 0.5628\n",
            "Epoch 170/300\n",
            "28709/28709 [==============================] - 10s 343us/step - loss: 0.3366 - accuracy: 0.8846 - val_loss: 1.8615 - val_accuracy: 0.5609\n",
            "Epoch 171/300\n",
            "28709/28709 [==============================] - 10s 340us/step - loss: 0.3217 - accuracy: 0.8920 - val_loss: 1.9412 - val_accuracy: 0.5631\n",
            "Epoch 172/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3265 - accuracy: 0.8910 - val_loss: 1.8707 - val_accuracy: 0.5642\n",
            "Epoch 173/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.3247 - accuracy: 0.8900 - val_loss: 1.8800 - val_accuracy: 0.5492\n",
            "Epoch 174/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3270 - accuracy: 0.8867 - val_loss: 1.8633 - val_accuracy: 0.5609\n",
            "Epoch 175/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.3223 - accuracy: 0.8917 - val_loss: 1.7806 - val_accuracy: 0.5578\n",
            "Epoch 176/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3206 - accuracy: 0.8916 - val_loss: 1.8443 - val_accuracy: 0.5561\n",
            "Epoch 177/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3265 - accuracy: 0.8901 - val_loss: 1.9000 - val_accuracy: 0.5651\n",
            "Epoch 178/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.3209 - accuracy: 0.8921 - val_loss: 1.8941 - val_accuracy: 0.5575\n",
            "Epoch 179/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3236 - accuracy: 0.8899 - val_loss: 1.8580 - val_accuracy: 0.5690\n",
            "Epoch 180/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3084 - accuracy: 0.8970 - val_loss: 1.9583 - val_accuracy: 0.5609\n",
            "Epoch 181/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.3170 - accuracy: 0.8938 - val_loss: 1.9014 - val_accuracy: 0.5584\n",
            "Epoch 182/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.3193 - accuracy: 0.8924 - val_loss: 1.9824 - val_accuracy: 0.5609\n",
            "Epoch 183/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3102 - accuracy: 0.8946 - val_loss: 1.8421 - val_accuracy: 0.5645\n",
            "Epoch 184/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3221 - accuracy: 0.8920 - val_loss: 1.8487 - val_accuracy: 0.5612\n",
            "Epoch 185/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.3242 - accuracy: 0.8909 - val_loss: 1.8235 - val_accuracy: 0.5587\n",
            "Epoch 186/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3315 - accuracy: 0.8889 - val_loss: 1.9054 - val_accuracy: 0.5567\n",
            "Epoch 187/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3169 - accuracy: 0.8937 - val_loss: 1.8652 - val_accuracy: 0.5626\n",
            "Epoch 188/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.3092 - accuracy: 0.8972 - val_loss: 1.8520 - val_accuracy: 0.5687\n",
            "Epoch 189/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3211 - accuracy: 0.8905 - val_loss: 1.8970 - val_accuracy: 0.5573\n",
            "Epoch 190/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3051 - accuracy: 0.8979 - val_loss: 1.9602 - val_accuracy: 0.5692\n",
            "Epoch 191/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3191 - accuracy: 0.8924 - val_loss: 1.9296 - val_accuracy: 0.5614\n",
            "Epoch 192/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3100 - accuracy: 0.8976 - val_loss: 1.8581 - val_accuracy: 0.5620\n",
            "Epoch 193/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3182 - accuracy: 0.8916 - val_loss: 1.8368 - val_accuracy: 0.5653\n",
            "Epoch 194/300\n",
            "28709/28709 [==============================] - 9s 331us/step - loss: 0.3135 - accuracy: 0.8960 - val_loss: 1.7656 - val_accuracy: 0.5692\n",
            "Epoch 195/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2997 - accuracy: 0.9001 - val_loss: 1.9151 - val_accuracy: 0.5626\n",
            "Epoch 196/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3183 - accuracy: 0.8933 - val_loss: 1.9214 - val_accuracy: 0.5681\n",
            "Epoch 197/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3115 - accuracy: 0.8953 - val_loss: 1.8880 - val_accuracy: 0.5701\n",
            "Epoch 198/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.2998 - accuracy: 0.9002 - val_loss: 1.9325 - val_accuracy: 0.5659\n",
            "Epoch 199/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3026 - accuracy: 0.8979 - val_loss: 1.8701 - val_accuracy: 0.5628\n",
            "Epoch 200/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3005 - accuracy: 0.9006 - val_loss: 1.9618 - val_accuracy: 0.5573\n",
            "Epoch 201/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3067 - accuracy: 0.8982 - val_loss: 2.0197 - val_accuracy: 0.5573\n",
            "Epoch 202/300\n",
            "28709/28709 [==============================] - 10s 340us/step - loss: 0.3090 - accuracy: 0.8979 - val_loss: 1.9190 - val_accuracy: 0.5600\n",
            "Epoch 203/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.3122 - accuracy: 0.8951 - val_loss: 1.8005 - val_accuracy: 0.5614\n",
            "Epoch 204/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3109 - accuracy: 0.8956 - val_loss: 1.8900 - val_accuracy: 0.5681\n",
            "Epoch 205/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3030 - accuracy: 0.8991 - val_loss: 1.9408 - val_accuracy: 0.5570\n",
            "Epoch 206/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.3152 - accuracy: 0.8947 - val_loss: 1.9486 - val_accuracy: 0.5628\n",
            "Epoch 207/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3013 - accuracy: 0.9009 - val_loss: 1.9544 - val_accuracy: 0.5595\n",
            "Epoch 208/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2973 - accuracy: 0.9035 - val_loss: 1.9179 - val_accuracy: 0.5687\n",
            "Epoch 209/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2908 - accuracy: 0.9036 - val_loss: 1.8385 - val_accuracy: 0.5656\n",
            "Epoch 210/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.2948 - accuracy: 0.9022 - val_loss: 1.9741 - val_accuracy: 0.5573\n",
            "Epoch 211/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3114 - accuracy: 0.8963 - val_loss: 1.8823 - val_accuracy: 0.5648\n",
            "Epoch 212/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3187 - accuracy: 0.8926 - val_loss: 1.8606 - val_accuracy: 0.5553\n",
            "Epoch 213/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.2905 - accuracy: 0.9040 - val_loss: 1.9665 - val_accuracy: 0.5542\n",
            "Epoch 214/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2886 - accuracy: 0.9040 - val_loss: 2.0004 - val_accuracy: 0.5620\n",
            "Epoch 215/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2922 - accuracy: 0.9040 - val_loss: 1.9020 - val_accuracy: 0.5620\n",
            "Epoch 216/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.3002 - accuracy: 0.8992 - val_loss: 1.9073 - val_accuracy: 0.5542\n",
            "Epoch 217/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2763 - accuracy: 0.9073 - val_loss: 2.0083 - val_accuracy: 0.5670\n",
            "Epoch 218/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2936 - accuracy: 0.9013 - val_loss: 1.9454 - val_accuracy: 0.5623\n",
            "Epoch 219/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2947 - accuracy: 0.9031 - val_loss: 1.9657 - val_accuracy: 0.5606\n",
            "Epoch 220/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3037 - accuracy: 0.8980 - val_loss: 1.9776 - val_accuracy: 0.5642\n",
            "Epoch 221/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3070 - accuracy: 0.8976 - val_loss: 1.8668 - val_accuracy: 0.5570\n",
            "Epoch 222/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.3103 - accuracy: 0.8987 - val_loss: 1.8404 - val_accuracy: 0.5573\n",
            "Epoch 223/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2866 - accuracy: 0.9053 - val_loss: 1.9516 - val_accuracy: 0.5575\n",
            "Epoch 224/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.3122 - accuracy: 0.8970 - val_loss: 1.9291 - val_accuracy: 0.5548\n",
            "Epoch 225/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2985 - accuracy: 0.9006 - val_loss: 1.8981 - val_accuracy: 0.5698\n",
            "Epoch 226/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2790 - accuracy: 0.9072 - val_loss: 1.9114 - val_accuracy: 0.5712\n",
            "Epoch 227/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2908 - accuracy: 0.9022 - val_loss: 1.9968 - val_accuracy: 0.5690\n",
            "Epoch 228/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2965 - accuracy: 0.9031 - val_loss: 1.9469 - val_accuracy: 0.5617\n",
            "Epoch 229/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2891 - accuracy: 0.9039 - val_loss: 1.9720 - val_accuracy: 0.5623\n",
            "Epoch 230/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2922 - accuracy: 0.9042 - val_loss: 1.8557 - val_accuracy: 0.5578\n",
            "Epoch 231/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.3003 - accuracy: 0.8997 - val_loss: 1.9342 - val_accuracy: 0.5617\n",
            "Epoch 232/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2812 - accuracy: 0.9073 - val_loss: 1.9691 - val_accuracy: 0.5561\n",
            "Epoch 233/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.2879 - accuracy: 0.9043 - val_loss: 2.0168 - val_accuracy: 0.5656\n",
            "Epoch 234/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2923 - accuracy: 0.9037 - val_loss: 2.0111 - val_accuracy: 0.5598\n",
            "Epoch 235/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2909 - accuracy: 0.9045 - val_loss: 2.0314 - val_accuracy: 0.5584\n",
            "Epoch 236/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2854 - accuracy: 0.9056 - val_loss: 1.8567 - val_accuracy: 0.5662\n",
            "Epoch 237/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2882 - accuracy: 0.9050 - val_loss: 1.8418 - val_accuracy: 0.5712\n",
            "Epoch 238/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.2875 - accuracy: 0.9058 - val_loss: 2.0095 - val_accuracy: 0.5706\n",
            "Epoch 239/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2756 - accuracy: 0.9090 - val_loss: 1.9290 - val_accuracy: 0.5578\n",
            "Epoch 240/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2881 - accuracy: 0.9050 - val_loss: 2.0537 - val_accuracy: 0.5642\n",
            "Epoch 241/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2887 - accuracy: 0.9063 - val_loss: 1.9827 - val_accuracy: 0.5623\n",
            "Epoch 242/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2776 - accuracy: 0.9080 - val_loss: 1.9846 - val_accuracy: 0.5662\n",
            "Epoch 243/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2858 - accuracy: 0.9064 - val_loss: 1.9376 - val_accuracy: 0.5595\n",
            "Epoch 244/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2762 - accuracy: 0.9077 - val_loss: 2.0113 - val_accuracy: 0.5645\n",
            "Epoch 245/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2893 - accuracy: 0.9053 - val_loss: 2.0187 - val_accuracy: 0.5667\n",
            "Epoch 246/300\n",
            "28709/28709 [==============================] - 10s 331us/step - loss: 0.2920 - accuracy: 0.9030 - val_loss: 1.9405 - val_accuracy: 0.5648\n",
            "Epoch 247/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2821 - accuracy: 0.9096 - val_loss: 1.9979 - val_accuracy: 0.5548\n",
            "Epoch 248/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2816 - accuracy: 0.9079 - val_loss: 2.0069 - val_accuracy: 0.5637\n",
            "Epoch 249/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2796 - accuracy: 0.9102 - val_loss: 1.9789 - val_accuracy: 0.5520\n",
            "Epoch 250/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2683 - accuracy: 0.9120 - val_loss: 2.0552 - val_accuracy: 0.5634\n",
            "Epoch 251/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2871 - accuracy: 0.9050 - val_loss: 1.9836 - val_accuracy: 0.5665\n",
            "Epoch 252/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2927 - accuracy: 0.9031 - val_loss: 1.9484 - val_accuracy: 0.5651\n",
            "Epoch 253/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2890 - accuracy: 0.9055 - val_loss: 1.9025 - val_accuracy: 0.5659\n",
            "Epoch 254/300\n",
            "28709/28709 [==============================] - 10s 339us/step - loss: 0.2796 - accuracy: 0.9075 - val_loss: 1.9895 - val_accuracy: 0.5578\n",
            "Epoch 255/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2817 - accuracy: 0.9076 - val_loss: 2.0677 - val_accuracy: 0.5522\n",
            "Epoch 256/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2823 - accuracy: 0.9066 - val_loss: 2.1450 - val_accuracy: 0.5561\n",
            "Epoch 257/300\n",
            "28709/28709 [==============================] - 10s 333us/step - loss: 0.2925 - accuracy: 0.9044 - val_loss: 1.9489 - val_accuracy: 0.5673\n",
            "Epoch 258/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2726 - accuracy: 0.9081 - val_loss: 1.9853 - val_accuracy: 0.5617\n",
            "Epoch 259/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2774 - accuracy: 0.9103 - val_loss: 2.0362 - val_accuracy: 0.5581\n",
            "Epoch 260/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2825 - accuracy: 0.9072 - val_loss: 2.0688 - val_accuracy: 0.5514\n",
            "Epoch 261/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2825 - accuracy: 0.9074 - val_loss: 1.9756 - val_accuracy: 0.5609\n",
            "Epoch 262/300\n",
            "28709/28709 [==============================] - 10s 340us/step - loss: 0.2792 - accuracy: 0.9099 - val_loss: 2.0271 - val_accuracy: 0.5609\n",
            "Epoch 263/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2798 - accuracy: 0.9086 - val_loss: 1.9199 - val_accuracy: 0.5598\n",
            "Epoch 264/300\n",
            "28709/28709 [==============================] - 10s 332us/step - loss: 0.2830 - accuracy: 0.9077 - val_loss: 2.0396 - val_accuracy: 0.5578\n",
            "Epoch 265/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2727 - accuracy: 0.9090 - val_loss: 2.0891 - val_accuracy: 0.5550\n",
            "Epoch 266/300\n",
            "28709/28709 [==============================] - 10s 339us/step - loss: 0.2830 - accuracy: 0.9091 - val_loss: 2.0364 - val_accuracy: 0.5564\n",
            "Epoch 267/300\n",
            "28709/28709 [==============================] - 10s 341us/step - loss: 0.2752 - accuracy: 0.9092 - val_loss: 2.0127 - val_accuracy: 0.5609\n",
            "Epoch 268/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.2723 - accuracy: 0.9107 - val_loss: 2.1010 - val_accuracy: 0.5634\n",
            "Epoch 269/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2876 - accuracy: 0.9054 - val_loss: 2.0922 - val_accuracy: 0.5659\n",
            "Epoch 270/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.2757 - accuracy: 0.9076 - val_loss: 1.9826 - val_accuracy: 0.5665\n",
            "Epoch 271/300\n",
            "28709/28709 [==============================] - 10s 340us/step - loss: 0.2790 - accuracy: 0.9097 - val_loss: 2.0092 - val_accuracy: 0.5534\n",
            "Epoch 272/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2627 - accuracy: 0.9149 - val_loss: 2.0382 - val_accuracy: 0.5617\n",
            "Epoch 273/300\n",
            "28709/28709 [==============================] - 10s 340us/step - loss: 0.2703 - accuracy: 0.9115 - val_loss: 2.1219 - val_accuracy: 0.5545\n",
            "Epoch 274/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2685 - accuracy: 0.9140 - val_loss: 2.0696 - val_accuracy: 0.5536\n",
            "Epoch 275/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.2856 - accuracy: 0.9087 - val_loss: 1.8986 - val_accuracy: 0.5584\n",
            "Epoch 276/300\n",
            "28709/28709 [==============================] - 10s 339us/step - loss: 0.2757 - accuracy: 0.9094 - val_loss: 2.0168 - val_accuracy: 0.5548\n",
            "Epoch 277/300\n",
            "28709/28709 [==============================] - 10s 340us/step - loss: 0.2743 - accuracy: 0.9129 - val_loss: 2.0288 - val_accuracy: 0.5603\n",
            "Epoch 278/300\n",
            "28709/28709 [==============================] - 10s 339us/step - loss: 0.2887 - accuracy: 0.9080 - val_loss: 2.0150 - val_accuracy: 0.5695\n",
            "Epoch 279/300\n",
            "28709/28709 [==============================] - 10s 341us/step - loss: 0.2681 - accuracy: 0.9108 - val_loss: 1.9897 - val_accuracy: 0.5729\n",
            "Epoch 280/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2808 - accuracy: 0.9096 - val_loss: 1.9433 - val_accuracy: 0.5609\n",
            "Epoch 281/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2762 - accuracy: 0.9092 - val_loss: 2.1028 - val_accuracy: 0.5673\n",
            "Epoch 282/300\n",
            "28709/28709 [==============================] - 10s 334us/step - loss: 0.2681 - accuracy: 0.9126 - val_loss: 2.0321 - val_accuracy: 0.5603\n",
            "Epoch 283/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2689 - accuracy: 0.9135 - val_loss: 2.1088 - val_accuracy: 0.5553\n",
            "Epoch 284/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2737 - accuracy: 0.9123 - val_loss: 2.0134 - val_accuracy: 0.5659\n",
            "Epoch 285/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2671 - accuracy: 0.9130 - val_loss: 1.9517 - val_accuracy: 0.5548\n",
            "Epoch 286/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.2634 - accuracy: 0.9150 - val_loss: 1.9870 - val_accuracy: 0.5634\n",
            "Epoch 287/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2692 - accuracy: 0.9130 - val_loss: 1.9936 - val_accuracy: 0.5500\n",
            "Epoch 288/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.2721 - accuracy: 0.9104 - val_loss: 1.9690 - val_accuracy: 0.5528\n",
            "Epoch 289/300\n",
            "28709/28709 [==============================] - 10s 338us/step - loss: 0.2674 - accuracy: 0.9130 - val_loss: 2.0674 - val_accuracy: 0.5534\n",
            "Epoch 290/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2819 - accuracy: 0.9107 - val_loss: 1.9686 - val_accuracy: 0.5522\n",
            "Epoch 291/300\n",
            "28709/28709 [==============================] - 10s 339us/step - loss: 0.2729 - accuracy: 0.9101 - val_loss: 1.9983 - val_accuracy: 0.5553\n",
            "Epoch 292/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2675 - accuracy: 0.9139 - val_loss: 1.9723 - val_accuracy: 0.5508\n",
            "Epoch 293/300\n",
            "28709/28709 [==============================] - 10s 336us/step - loss: 0.2799 - accuracy: 0.9116 - val_loss: 1.9748 - val_accuracy: 0.5483\n",
            "Epoch 294/300\n",
            "28709/28709 [==============================] - 10s 339us/step - loss: 0.2628 - accuracy: 0.9151 - val_loss: 2.1349 - val_accuracy: 0.5592\n",
            "Epoch 295/300\n",
            "28709/28709 [==============================] - 10s 343us/step - loss: 0.2821 - accuracy: 0.9106 - val_loss: 1.9307 - val_accuracy: 0.5567\n",
            "Epoch 296/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2494 - accuracy: 0.9176 - val_loss: 2.0394 - val_accuracy: 0.5478\n",
            "Epoch 297/300\n",
            "28709/28709 [==============================] - 10s 337us/step - loss: 0.2788 - accuracy: 0.9095 - val_loss: 1.9581 - val_accuracy: 0.5690\n",
            "Epoch 298/300\n",
            "28709/28709 [==============================] - 10s 335us/step - loss: 0.2611 - accuracy: 0.9162 - val_loss: 2.1158 - val_accuracy: 0.5564\n",
            "Epoch 299/300\n",
            "28709/28709 [==============================] - 10s 342us/step - loss: 0.2739 - accuracy: 0.9142 - val_loss: 2.0847 - val_accuracy: 0.5581\n",
            "Epoch 300/300\n",
            "28709/28709 [==============================] - 10s 339us/step - loss: 0.2732 - accuracy: 0.9123 - val_loss: 1.9297 - val_accuracy: 0.5598\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UftfNIIs1Jlu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}